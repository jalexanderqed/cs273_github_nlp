Hi

I use RocksDB in my NoSQL to store data, but meet a strange problem when I try to optimize get performance. 

First, I insert 200000 4KB data into RocksDB.

The Get performance for RocksDB is very high in my benchmark. The code using Go like below:

```
var tt time.Duration = 0
n := 200000
for i := 0; i < n; i++ {
    t1 := time.Now()
    db.Get([]byte(fmt.Sprintf("%d", i+1)))
    tt += time.Now().Sub(t1)
}

fmt.Printf("gt:%s\n", tt.String())
```

For 200000 Get, it will cost about 2.78s (70K RPS) in my node, this is very fast. But when I benchmark it with network, the performance reduces too much. The service flow may like this:

```
var tt time.Duration = 0
for {
    //read key from socket

    t1 := time.Now()
    v := db.Get(key)
    tt += time.Now().Sub(t1)

    //write value to socket
}
//println total Get time after socket closed
fmt.Printf("gt:%s\n", tt.String())

//in another shell, I do the benchmark, using 1 client and 200000 request number, like this:
ledis-benchmark -c=1 -n=200000 -t=get 
```

I hope the total get time may be same as the first, but to my surprise, it increases 30% time, about 3.6s.

Maybe the network handling influences the get performance, but I don't know. 

Then I do another benchmark, sleep little time after every get, like this:

```
var tt time.Duration = 0
n := 200000
for i := 0; i < n; i++ {
    t1 := time.Now()
    db.Get([]byte(fmt.Sprintf("%d", i+1)))
    tt += time.Now().Sub(t1)
    time.Sleep(10 * time.Microsecond)
}

fmt.Printf("gt:%s\n", tt.String())
```

The total time increases too, about 11% (3.0s). 

This result confuses me very much, and I let @presbrey and @aredlich help me do the same benchmark and they get the same result, the performance degrades too much even in @aredlich machine.

My rocksdb configuration:

```
background_threads = 4
high_priority_background_threads = 1
max_background_compactions = 3
max_background_flushes = 1
block_size = 64 KB
write_buffer_size = 64 MB
max_write_buffer_num = 2
MaxBytesForLevelBase = 512 MB
target_file_size_base = 64 MB
cache_size = 512 MB
enable_statistics = true
stats_dump_period_sec = 5
level0_file_num_compaction_trigger = 8
max_bytes_for_level_multiplier = 8
```

RocksDB: 3.5 version
System: Linux 
CPU: 4x i5 3.10GHz
Mem: 16GB
Disk: HDD 

Anyone meets this problem? Thank you very much. 

