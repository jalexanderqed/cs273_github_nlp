I have a use-case where sequential read throughput is of primary importance. In order to benchmark RocksDB, I created 10 million records worth of dummy data. In this data the key is always 32 bytes long (an md5 hash) and the value part is around 300 to 500 bytes. The value part is a serialized JSON map which has english data (randomly generated).

I loaded this data into a RocksDB database with the following parameters (8MB block size, 128MB target file size, LZ4 compression and no bloom filters). After loading in bulk mode, I compacted to make sure everything is in order for efficient iteration.

At this point, I used `ldb` to `scan` through the whole database and measured the total time taken and rate. Here are the results

``` bash
time ldb --db=testdb scan | pv -blrac > /dev/null
  10M [ 778k/s] [ 778k/s]

real    0m12.845s
user    0m13.100s
sys     0m5.964s
```

> NOTE: the `pv` command measures progress of the command and does not add any significant overhead (any CPU occupied by it is anyway on a different core and it did not max out that other core).

To get an idea of what the best possible throughput would be on my hardware. I dumped all the records into a plain file and compressed it using lz4 command line tool (I made sure to not use lz4hc just like I had within RocksDB configuration). Here are the results for iterating through the data in this file.

``` bash
time cat testdb.lz4 | lz4c -d | pv -lracb > /dev/null
  10M [1.96M/s] [1.96M/s]

real    0m5.114s
user    0m3.568s
sys     0m1.968s
```

As you can see from the above, the plain file iteration was 2.5x times faster than RocksDB iteration. I understand that there is some processing overhead within RocksDB owing to its higher internal complexity but I was expecting a much lower multiplier.

I badly want to avoid writing a new abstraction to handle my specific use-case and just want to tune RocksDB to yield better performance if possible.

