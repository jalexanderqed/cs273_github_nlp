I have RocksDB running in PlainTable configuration. Keys are always 8 bytes long, and values are multiples of 5 bytes long. In the log, I get entries such as the following (I've added line breaks for better readability):

``` json
2016/01/06-20:16:57.930607 7f970ed53700 EVENT_LOG_v1
{"time_micros": 1452111417930566, "cf_name": "default", "job": 3, "event": "table_file_creation",
 "file_number": 7715, "file_size": 2097640, "table_properties": {
    "data_size": 2097159, "index_size": 0, "filter_size": 0, "raw_key_size": 2019136,
    "raw_average_key_size": 16, "raw_value_size": 708945, "raw_average_value_size": 5.61781,
    "num_data_blocks": 1, "num_entries": 126196, "filter_policy_name": "",
    "rocksdb.plain.table.encoding.type": "",
    "rocksdb.prefix.extractor.name": "rocksdb.FixedPrefix.8"}}
```

Note the `"raw_average_key_size": 16` - that value should be `8`. In my merge operator, I even added an `assert(key.size() == 8);`, just to be absolutely sure.

This is on RocksDB 3.13.1. Any ideas on what could be wrong? Here is my RocksDB configuration:

``` cpp
  // Plaintable
  rocksdb::PlainTableOptions plain_table_options;
  plain_table_options.user_key_len = 8;
  plain_table_options.bloom_bits_per_key = 10;
  plain_table_options.hash_table_ratio = 0.75;
  options.table_factory.reset(rocksdb::NewPlainTableFactory(plain_table_options));

  options.allow_mmap_reads = true;
  options.allow_mmap_writes = false;
  options.compression = rocksdb::kNoCompression;

  // create prefix extractor over entire key
  options.prefix_extractor.reset(rocksdb::NewFixedPrefixTransform(8));

  // Use hash link list memtable to change binary search to hash lookup in mem table
  // in write mode, use vector memtable
  if(mode == Mode::WriteOnly) {
    options.memtable_factory.reset(new rocksdb::VectorRepFactory);    
  } else {
    options.memtable_factory.reset(rocksdb::NewHashSkipListRepFactory(1024*1024));
  }

  // Enable bloom filter for hash table to reduce memory accesses (usually means
  // CPU cache misses) when reading from mem table to one, for the case where key
  // is not found in mem tables
  options.memtable_prefix_bloom_bits = 10000000;
  options.memtable_prefix_bloom_probes = 6;

  // Tune compaction so that, a full compaction is kicked off as soon as we have
  // two files. We hack the parameter of universal compaction:
  options.compaction_style = rocksdb::kCompactionStyleUniversal;
  options.compaction_options_universal.size_ratio = 10;
  options.compaction_options_universal.min_merge_width = 2;
  options.compaction_options_universal.max_size_amplification_percent = 1;
  options.level0_file_num_compaction_trigger = 1;
  options.level0_slowdown_writes_trigger = 16;
  options.level0_stop_writes_trigger = 24;

  // Tune bloom filter to minimize memory accesses:
  options.bloom_locality = 1;

  // Use one mem table at one time. Its size is determined by the full compaction
  // interval we want to pay. We tune compaction such that after every flush, a
  // full compaction will be triggered, which costs CPU. The larger the mem table
  // size, the longer the compaction interval will be, and at the same time, we
  // see less memory efficiency, worse query performance and longer recovery time
  // when restarting the DB.
  options.write_buffer_size = 32 << 20;  // 32Mb
  options.max_write_buffer_number = 2;
  options.min_write_buffer_number_to_merge = 1;

  // Multiple DBs sharing the same compaction pool of `num_threads`.
  // we have one thread for messaging, one thread for flushing, and
  // at least one thread for compacting. If num_threads > 3, put all 
  // remaining threads into compaction.
  int num_background_threads = num_threads > 3 ? num_threads - 2 : 1;
  options.max_background_compactions = num_background_threads;
  options.max_background_flushes = 1;
  options.env->SetBackgroundThreads(1, rocksdb::Env::Priority::HIGH);
  options.env->SetBackgroundThreads(num_background_threads, rocksdb::Env::Priority::LOW);

  // Settings for WAL logs:
  options.disableDataSync = 1;
  options.bytes_per_sync = 2 << 20;
```

