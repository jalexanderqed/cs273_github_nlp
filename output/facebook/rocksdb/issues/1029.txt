hi， i am trying to use rocksdb in java. the performance drop from 100+ms/10000 queries to 200+s/10000 queries, Anyone know why?, the test code is as following

```
  public static void main(String args[]) throws RocksDBException {
    Options options = PredefinedOptions.DEFAULT.createOptions()
        .setCreateIfMissing(true).setWriteBufferSize(128 * 1204 * 1024);
    File rocksDbPath = new File("db");
    final RocksDB db = RocksDB.open(options, rocksDbPath.getAbsolutePath());
    Thread th = new Thread(new Runnable() {
      private int round = 0;
      private Random x = new Random();
      @Override
      public void run() {
        for (int j = 0; j < 100; j++) {
          long start = System.currentTimeMillis();
          for (long i = 0; i < 100000L; i++) {
            try {
              db.put(Bytes.toBytes(j * 100000L + i), Bytes.toBytes(RandomWord.get()));
            } catch (RocksDBException e) {
              e.printStackTrace();
            }
          }
          logger.info("init round {}, step {}, put cost {} ms", round, j,
              System.currentTimeMillis() - start);
        }
          long startTime = System.currentTimeMillis();
          File localBackupPath = new File("backup-" + round);
          localBackupPath.mkdirs();
          try (BackupEngine backupEngine = BackupEngine.open(Env.getDefault(),
              new BackupableDBOptions(localBackupPath.getAbsolutePath()))) {
            backupEngine.createNewBackup(db);
          } catch (RocksDBException e) {
            e.printStackTrace();
          }
          long endTime = System.currentTimeMillis();
          logger.info("round {} new backup cost {}", round, endTime - startTime);
        while (true) {
          round++;
          long start = System.currentTimeMillis();
          logger.info("start round {}", round);
          for (long i = 0; i < 10000L; i++) {
            try {
              db.get(Bytes.toBytes((long) x.nextInt(100) * 100000 + x.nextInt(100000)));
            } catch (RocksDBException e) {
              e.printStackTrace();
            }
          }
          logger.info("round {}, 10000 get cost {} ms", round, System.currentTimeMillis() - start);
        }
      }
    });
    th.start();
    try {
      th.join();
    } catch (InterruptedException e) {
      e.printStackTrace();
    }
  }
```

@wenlonglwl I am not quite sure what your code is trying to demonstrate performance wise. It seems that you put 10,000,000,000 key/value pairs, and then do a backup, and then in a loop that never ends you attempt to retrieve 10,000 random key/value pairs.

I don't see how this code is meant to show a performance slowdown between before and after doing the backup?

I prefer to use the FB group or email list for questions, but github encourages this via the "question" label. 

With 10,000 queries in 200 seconds you get ~50 QPS. Does backup displace hot data from the cache so that you fall back to reading it from disk after backup?

the same code， when i remove the backup part, i compare the performance between with and without the backup part of code~

