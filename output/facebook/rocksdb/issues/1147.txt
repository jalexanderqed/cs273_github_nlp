Hello,

I must be doing something wrong because when I try to open a 5.3gb database for read-only operation the process hangs for about a minute and then gets killed.

The database has ten column families (which I pass during the open). The same code works fine for a smaller database.

These are the column family options I use:

``` c++
ColumnFamilyOptions options = ColumnFamilyOptions();
options.OptimizeForPointLookup(8);
options.OptimizeLevelStyleCompaction();
```

These are the database options I use:

``` c++
DBOptions options;
options.IncreaseParallelism();
```

If I strace the program, I see that it issues tons of `read()` calls for 32768 byte chunks and calls `brk()` every now and then. I did try a few additional options (e.g. `allow_mmap_reads`) but they don't seem to help.

Is there anything I'm doing wrong, or not doing, that could make this work for a database of this size and bigger? Any special options etc.?

Hi,
Who kills your database instance? Is it an operating system (Out-of-memory
killer maybe)? Or process crashes itself?

ср, 1 июн. 2016 г. в 16:53, Elad Efrat notifications@github.com:

> Hello,
> 
> I must be doing something wrong because when I try to open a 5.3gb
> database for read-only operation the process hangs for about a minute and
> then gets killed.
> 
> The database has ten column families (which I pass during the open). The
> same code works fine for a smaller database.
> 
> These are the column family options I use:
> 
> ColumnFamilyOptions options = ColumnFamilyOptions();
> options.OptimizeForPointLookup(8);
> options.OptimizeLevelStyleCompaction();
> 
> These are the database options I use:
> 
> DBOptions options;
> options.IncreaseParallelism();
> 
> If I strace the program, I see that it issues tons of read() calls for
> 32768 byte chunks and calls brk() every now and then. I did try a few
> additional options (e.g. allow_mmap_reads) but they don't seem to help.
> 
> Is there anything I'm doing wrong, or not doing, that could make this work
> for a database of this size and bigger? Any special options etc.?
> 
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> https://github.com/facebook/rocksdb/issues/1147, or mute the thread
> https://github.com/notifications/unsubscribe/AAIAh9MQNRZoiPeDkbTB-ZFjN5I0yTr2ks5qHVacgaJpZM4IrX6x
> .

The OS kills it due to high memory usage, yeah.

I see that I have a `.log` file in the database directory. Removing it fixes the issue, but I don't know if it's safe to do so and why do I have to do it manually. Perhaps it's not properly closed/flushed during write, which forces it to enter recovery when it's opened (again). I'm going to rebuild the database (in Java), this time explicitly calling `compactRange` and `flush` with each column family's handle.

EDIT: Explicitly compacting/flushing each column family handle after the batched write during database creation fixed the issue. I now have a resulting database with an empty log (so it's smaller too) and opening it succeeds quickly. Sorry for the noise!

