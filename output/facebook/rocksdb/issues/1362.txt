in https://github.com/facebook/rocksdb/wiki/RocksDB-Bloom-Filter
it is written:
We are working on a new Bloom filter option called "full filter" which contains a filter for all keys in the SST file. This may improve read performance, because it avoids traveling in a complicated SST format. However, it requires more memory to build, because all keys must be in-memory for a given SST file.

Why is it required to store all the keys in-memory?
Can't you just add each block keys to the file bloom filter during the file creation?

To be accurate, we keep 4-byte hash for each key while building the SST file. The reason we need to do that is that, we can't know before hand how many bytes the bloom filter should use. The way we are implementing it is to remember all the hash values, and in the end, allocate the filter block with the size based on number of keys and fill them.

We may be able to avoid it if we redesign the bloom filter data structure. We are not working on it though.

