Is there a known issue with random writes on RocksDb Java?  I have recently ported an application from the Java port of LevelDb and see comparable performance for sequential writes, but significantly worse performance for random writes (3-4 times worse and degrading over time).  In my scenario, I'm batch loading about 10 million rows of data that is randomly ordered (basically building an index to another RocksDB table).

The Java benchmarks you've published do not include the numbers from the random write tests: https://github.com/facebook/rocksdb/wiki/RocksJava-Performance-on-Flash-Storage. Can you elaborate (or maybe publish the data for all the benchmarks you run on C++?).

I've been using 3.8 on OSX 10.9.4.

thanks much.

@lwhite1 can you add the options used with leveldb and with rocksdb benchmarks ?

Options for Leveldb (Pure Java port)
        options.blockRestartInterval(32);
        options.writeBufferSize(20 \* MB);
        options.cacheSize(2000 \* MB);
        options.maxOpenFiles(3500);
        options.compressionType(CompressionType.SNAPPY);
        ByteKeyComparator comparator = new ByteKeyComparator();
        options.comparator(comparator);

Options for RocksDB Java (I've tried a variety of settings, including only setting some basic things)
            options.setAllowOsBuffer(true);
            options.setWriteBufferSize(32 \* MB);
            options.setMaxWriteBufferNumber(4);
            options.setMinWriteBufferNumberToMerge(2);
            options.setMaxOpenFiles(5000);
            options.setCompressionType(CompressionType.SNAPPY_COMPRESSION);
            options.getEnv().setBackgroundThreads(6, RocksEnv.COMPACTION_POOL);
            options.getEnv().setBackgroundThreads(2, RocksEnv.FLUSH_POOL);
            options.setMaxBackgroundCompactions(6); // how many cores to allocate to compaction?
            options.setMaxBackgroundFlushes(2);
            options.setCompactionStyle(CompactionStyle.LEVEL);
            options.setTargetFileSizeBase(options.maxBytesForLevelBase() / 10);

// I started with lower settings on the triggers and increased them as writes were stalling
            options.setLevelZeroFileNumCompactionTrigger(10);
            options.setLevelZeroSlowdownWritesTrigger(25);
            options.setLevelZeroStopWritesTrigger(35);

options.setNumLevels(4);
options.setMaxBytesForLevelBase(640 \* MB);
options.setMaxBytesForLevelMultiplier(10); // each level is n times bigger than prev

options.setAllowMmapReads(true);        // must be true if setting a PlainTableConfig
Filter bloomFilter = new BloomFilter(10);  // 10 bits per key = ~ 1% false positive;
BlockBasedTableConfig bbTableConfig = new BlockBasedTableConfig();
bbTableConfig.setIndexType(org.rocksdb.IndexType.kBinarySearch);
bbTableConfig.setCacheIndexAndFilterBlocks(true);
bbTableConfig.setFilter(bloomFilter);
options.setTableFormatConfig(bbTableConfig);

ComparatorOptions comparatorOptions = new ComparatorOptions();
RdbByteKeyComparator comparator = new RdbByteKeyComparator(comparatorOptions);
options.setComparator(comparator);

@lwhite1 we know that there is currently a limitation from a performance perspective with using a custom comparator in Java. Did you also benchmark random writes without having a Java comparator set in the `Options` ? RocksDB is using a bytewise comparator by default.

@fyrz I haven't tried the standard comparator. Unfortunately, it doesn't meet the requirements for my application. Is there any way to work around the limitation or a timeline for fixing it?

@lwhite1 i think there is no workaround because the problem is that there is a locking issue and the parts need to be moved to thread local storage. We have it on our todo list and i think it is one of the next things to change.

lwhite1: You are currently using
    options.setAllowMmapReads(true); // must be true if setting a PlainTableConfig
But you are not using a PlainTableConfig, you are using BlockBasedTableConfig. You might get better performance if you use
    options.setAllowMmapReads(false).
However, it is unlikely that the above change will materially impact your write performance.

fyrz: thanks for the info about using ThreadLocalStorage instead of locks. 

Thank you @fyrz and @dhruba for the info. I'll be following the project and look to port when the issue is resolved. 
Bit of a crazy question, maybe: If I were to change the default comparator in the C++ RocksDB and recompile that, is that a potential work-around for the short-term?

lwhite1: yes, your proposal to change the default c++ comparator is a short-term workaround for your problem. 

@lwhite1 I did the last days some performance benchmarks and narrowed down the location where the time is spent.

If you implement a `BytewiseComparator` using the Java API you will have code that is about 5-8 times slower. That`s related to the problem that we got a transition between native code and Java code. As these transitions happen frequently you will notice decreasing performance using a Java comparator implementation.

Another thing is that the amount of `compare` method calls increases over time with the size of the database which accounts to a significant loss of insert performance (with a factor of 5-8 times slower compare calls)

That is not related to multi-threading and happens also using a single threaded invocation.

The position in the code where most of the times is lost is in the method call: `CallIntMethod` (https://github.com/facebook/rocksdb/blob/master/java/rocksjni/comparatorjnicallback.cc#L65). At the moment there is no way to improve performance there. 

So if you need to implement a custom comparator for production use. You will have to implement a C++ comparator and use this. (@adamretter will outline a proper way to do this in the Wiki in the near future). At least if you want to keep more than a million records in your database.

@dhruba FYI

Thank you for reporting this issue and appreciate your patience. We've  notified the core team for an update on this issue. We're looking for a response within the next 30 days or the issue may be closed.

