We have few boxes with 1000's of column families and we are observing the WAL size growing to 100GB in a matter of 3-4 days, with a very modest write rate ( > 1000 writes/sec)

write_buffer_size = 4MB , max_write_buffer_number = 2 , max_total_wal_size = 0 , #of column families = 1500 [rocksdb 3.11.2]

As per the comment in options.h , if max_total_wal_size is not set (default of 0), then it should set that value to be = [sum of all write_buffer_size \* max_write_buffer_number] \* 2. In our case of 1500 tablets, it should be = (4 \* 1500) *2 *2 = 24GB . As per comments of that setting, it should force flush of tablets in old WAL files once this limit is crossed, but this doesn't explain WAL growing to 100 GB.

One hypothesis:
We might have few tablets which has very slow write rate , few bytes every 5 mins, taking a long time to fill even the 4MB memtable, causing lots of old log files to sit around ?

Is this expected with lots of column families, has any one seen or debugged such an issue ?

Thanks , Jayadev

To clarify terminology, a "tablet" in our system is mapped 1:1 to a column family in RocksDB

Yes it is expected. Usually we use max_total_wal_size to solve the problem.

Please re-open if you are still seeing this problem with the fix proposed by Siying.

